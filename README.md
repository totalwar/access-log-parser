Имеется access-лог web-сервера. Файл со следующей структурой.
```
192.168.32.181 - - [14/06/2017:16:47:02 +1000] "PUT /rest/v1.4/documents?zone=default&_rid=6076537c HTTP/1.1" 200 2 44.510983 "-" "@list-item-updater" prio:0
192.168.32.181 - - [14/06/2017:16:47:02 +1000] "PUT /rest/v1.4/documents?zone=default&_rid=7ae28555 HTTP/1.1" 200 2 23.251219 "-" "@list-item-updater" prio:0
192.168.32.181 - - [14/06/2017:16:47:02 +1000] "PUT /rest/v1.4/documents?zone=default&_rid=e356713 HTTP/1.1" 200 2 30.164372 "-" "@list-item-updater" prio:0
```

У каждой записи есть HTTP-код ответа (9-е поле, в первом примере "200") и время обработки запроса в миллисекундах (11-е поле, в первом примере: "44.510983"). Каждый день оператор выполняет анализ лога локализуя диапазоны времени, когда доля отказов сервиса превышала указанную границу. С этими инцидентами позже разбирается группа разработки. Требуется написать алгоритм читающий access-лог и выполняющий анализ отказов автоматически.
Отказом считается запрос завершившийся с любым 500-м кодом возврата (5xx) или обрабатываемый дольше чем указанный интервал времени.
На входе программе дается:
- поток данных из access-лог'а;
- минимально допустимый уровень доступности (проценты. Например, "99.9");
- приемлемое время ответа (миллисекунды. Например, "45").

На выходе программа предоставляет временные интервалы, в которые доля отказов системы превышала указанную границу, а также уровень доступности в этот интервал времени. Интервалы должны быть отсортированы по времени начала.
Пример использования программы:
```
$ cat access.log | java -jar analyze -u 99.9 -t 45
13:32:26 13:33:15 94.5
15:23:02 15:23:08 99.8
```

Требования и ограничения.
-------------------------

- предполагается, что входящий лог бесконечный и не поместится в оперативную память полностью
- время записи в логах имеет не убывающее значение
- разработчику нужно учитывать, что программа должна обрабатывать большие объемы данных и, при выборе решений, ориентироваться на оптимизацию расхода системных ресурсов (процессор, память)
- допускается использования версии JDK 8-11 и более поздних;
- допускается использование сторонних библиотек;
- сборка проекта должна осуществляться утилитой Apache Maven;
- проект должен содержать автоматические тесты фиксирующие поведение системы в объеме по вашему усмотрению;
- результатом сборки должен являться self-executable jar-файл, который можно запустить командой "java -jar ..."

* * *

Реализации
----------
Первая реализация `Antlr4BasedParser` - это честный antlr парсер по мотивам грамматики common log format,
но с доработками под приведенный в задании пример. Самый медленный вариант, тут без неожиданностей.

Вторая реализация `CsvBasedParser` - применение библиотеки apache commons csv,
с переопределенным разделителем в виде пробела, а не запятой. Корректно токенизирует строку в кавычках.
По производительности прирост в 5 раз.

Третья реализация через стандартный `StringTokenizer`. Не токенизирует строки в кавычках,
так что приходится собирать по частям. Прирост в 1,5 раза.

Четвертая реализация кастомный Tokenizer с использованием Vector API.
Ускорение за счет обработки сразу 32 байт за один такт (может быть больше/меньше, зависит от камня
и поддерживаемых SIMD инструкций). Алгоритм тут следующий: в один регистр загружаем чанк обрабатываемой строки,
в другой регистр маску (значение символа-разделителя), если маска отработала - берем первое вхождение,
иначе подгружаем следующий чанк из 32 байт и т.д. Прирост в 2 раза.

Бенчмарки
---------

Сравнение LocalDateTime.parse vs кастом парсер из строки.
Входной массив - 500 дат в рандомном порядке.
```
Benchmark                                Mode  Cnt    Score    Error  Units
ParseDateBenchmarks.testCustomDateUtils  avgt    5   13,330 ±  0,253  us/op
ParseDateBenchmarks.testLocalDateTime    avgt    5  460,033 ±  7,658  us/op
```

Бенч разных реализаций парсера common log format
(входной массив - файл из задания access.log ~7000 строк), 
где baseline это пустая имплементация, то есть замер чистого времени i/o.
```
ParserBenchmarks.testAntlr4Parser        avgt    5   58,736 ± 13,804  ms/op
ParserBenchmarks.testCsvBasedParser      avgt    5   13,110 ±  0,673  ms/op
ParserBenchmarks.testParserBaseline      avgt    5    0,473 ±  0,030  ms/op
ParserBenchmarks.testSimdBasedParser     avgt    5    4,657 ±  0,149  ms/op
ParserBenchmarks.testTokenBasedParser    avgt    5    8,782 ±  0,537  ms/op
```

Простой нагрузочный тест (1 млн строк).
Данные генерируются скриптом `gen-sample.py`
```
Benchmark                              Mode  Cnt    Score    Error  Units
LoadTestBenchmark.testSimdBasedParser  avgt    3  678,537 ± 20,099  ms/op
```

Профилирование
--------------

Внезапно в горячие методы всплывает `new String(byte[])` и `Reader.readLine()`.

Оптимизации
-----------

- Переключиться со стриминга на memory mapped file.
- Подробить файл на сегменты и обработать их параллельно в потоках.
- Не аллоцировать `String` до самого последнего момента, парсить исключительно сырые байтбуферы.
